import os
import time
import json
import tempfile
import wave
import pygame
import streamlit as st
import sounddevice as sd
import numpy as np
from openai import OpenAI
from pathlib import Path
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class VoiceOrdering:
    """60ì„¸ ì´ìƒ ì–´ë¥´ì‹ ì„ ìœ„í•œ OpenAI ìŒì„± ì£¼ë¬¸ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        
        self.client = OpenAI(api_key=api_key)
        
        # ì„ì‹œ ë””ë ‰í„°ë¦¬ ì„¤ì •
        self.tmp_dir = Path(tempfile.gettempdir()) / "voice_ordering"
        self.tmp_dir.mkdir(exist_ok=True)
        
        # pygame ì´ˆê¸°í™” (ìŒì„± ì¬ìƒìš©)
        if not pygame.get_init():
            pygame.mixer.pre_init(frequency=22050, size=-16, channels=2, buffer=512)
            pygame.mixer.init()
        
        print("[ìŒì„± ì£¼ë¬¸] ì´ˆê¸°í™” ì™„ë£Œ")
    
    def text_to_speech(self, text: str) -> None:
        """OpenAI TTS APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ ë° ì¬ìƒ"""
        try:
            print(f"[TTS] í…ìŠ¤íŠ¸: {text}")
            
            # í™”ë©´ì— TTS ë‚´ìš© í‘œì‹œ
            st.markdown("### ğŸ”Š AI ì•ˆë‚´")
            st.info(text)
            
            # OpenAI TTS API í˜¸ì¶œ
            response = self.client.audio.speech.create(
                model="tts-1",
                voice="nova",
                input=text,
                response_format="mp3"
            )
            
            # MP3 ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_file = self.tmp_dir / f"tts_{int(time.time())}.mp3"
            with open(temp_file, 'wb') as f:
                f.write(response.content)
            
            # pygameìœ¼ë¡œ ì¬ìƒ
            pygame.mixer.music.load(str(temp_file))
            pygame.mixer.music.play()
            
            # ì¬ìƒ ìƒíƒœ í‘œì‹œ
            with st.spinner("ğŸ”Š ìŒì„± ì¬ìƒ ì¤‘..."):
                # ì¬ìƒ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
                while pygame.mixer.music.get_busy():
                    time.sleep(0.1)
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(temp_file)
            print(f"[TTS] ì¬ìƒ ì™„ë£Œ")
            
            # ì¬ìƒ ì™„ë£Œ í›„ ì ì‹œ ëŒ€ê¸° (ì‚¬ìš©ìê°€ ìŒì„±ì„ ë“£ê³  ì´í•´í•  ì‹œê°„)
            time.sleep(1)
            
        except Exception as e:
            print(f"[TTS] ì˜¤ë¥˜: {e}")
            st.error(f"ìŒì„± ì¶œë ¥ ì˜¤ë¥˜: {e}")
    
    def detect_silence(self, audio_data, sample_rate, threshold=0.01, min_silence_duration=4.0):
        """ìŒì„± ë°ì´í„°ì—ì„œ ì¹¨ë¬µ êµ¬ê°„ ê°ì§€"""
        # ì˜¤ë””ì˜¤ ë°ì´í„° ì •ê·œí™”
        audio_data = audio_data.astype(np.float32) / 32768.0
        
        # RMS ì—ë„ˆì§€ ê³„ì‚° (0.1ì´ˆ ë‹¨ìœ„)
        frame_size = int(sample_rate * 0.1)
        energy_levels = []
        
        for i in range(0, len(audio_data), frame_size):
            frame = audio_data[i:i+frame_size]
            if len(frame) > 0:
                rms = np.sqrt(np.mean(frame**2))
                energy_levels.append(rms)
        
        # ì¹¨ë¬µ êµ¬ê°„ ì°¾ê¸°
        silence_frames = 0
        speech_detected = False
        
        for energy in energy_levels:
            if energy > threshold:
                silence_frames = 0
                speech_detected = True
            else:
                if speech_detected:  # ìŒì„±ì´ ê°ì§€ëœ í›„ì—ë§Œ ì¹¨ë¬µ ì¹´ìš´íŠ¸
                    silence_frames += 1
                    # 4ì´ˆ ì´ìƒ ì¹¨ë¬µì´ë©´ ì¤‘ë‹¨
                    if silence_frames * 0.1 >= min_silence_duration:
                        end_frame = len(energy_levels) - silence_frames
                        return int(end_frame * frame_size)
        
        return len(audio_data)

    def speech_to_text(self, max_duration: float = 20.0, silence_threshold: float = 4.0) -> str:
        """ë§ˆì´í¬ë¡œ ìŒì„±ì„ ë…¹ìŒí•˜ê³  OpenAI STT APIë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ (VAD ì ìš©)"""
        try:
            print("[STT] ìŒì„± ë…¹ìŒ ì‹œì‘...")
            
            # ë…¹ìŒ ìƒíƒœ í‘œì‹œ
            st.markdown("### ğŸ™ï¸ ìŒì„± ë…¹ìŒ ì¤‘...")
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ìŒì„± ë…¹ìŒ ì„¤ì •
            sample_rate = 16000
            channels = 1
            
            # ì‹¤ì‹œê°„ ë…¹ìŒì„ ìœ„í•œ í
            import queue
            audio_queue = queue.Queue()
            
            def audio_callback(indata, frames, time, status):
                audio_queue.put(indata.copy())
            
            # ë…¹ìŒ ì‹œì‘ ì „ ì‚¬ìš©ìì—ê²Œ ì¤€ë¹„ ì‹œê°„ ì œê³µ
            st.info("ğŸ™ï¸ ë§ˆì´í¬ ì•ì—ì„œ í¸ì•ˆí•˜ê²Œ ì•‰ì•„ì£¼ì„¸ìš”. ì¤€ë¹„ê°€ ë˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.")
            time.sleep(1)  # 1ì´ˆ ëŒ€ê¸°
            
            # ë…¹ìŒ ì‹œì‘
            with sd.InputStream(samplerate=sample_rate, channels=channels, 
                              callback=audio_callback, dtype=np.int16):
                
                recorded_data = []
                start_time = time.time()
                last_speech_time = start_time
                speech_detected = False
                
                while True:
                    current_time = time.time()
                    elapsed_time = current_time - start_time
                    
                    # ìµœëŒ€ ì‹œê°„ ì´ˆê³¼
                    if elapsed_time >= max_duration:
                        break
                    
                    # íì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    try:
                        data = audio_queue.get_nowait()
                        recorded_data.append(data)
                        
                        # ìŒì„± í™œë™ ê°ì§€
                        rms = np.sqrt(np.mean(data.astype(np.float32)**2)) / 32768.0
                        if rms > 0.01:  # ì„ê³„ê°’ë³´ë‹¤ í° ê²½ìš° ìŒì„±ìœ¼ë¡œ ê°„ì£¼
                            last_speech_time = current_time
                            speech_detected = True
                        
                        # ìŒì„± ê°ì§€ í›„ 5ì´ˆ ì¹¨ë¬µ ì‹œ ì¤‘ë‹¨ (4ì´ˆì—ì„œ 5ì´ˆë¡œ ì—°ì¥)
                        if speech_detected and (current_time - last_speech_time) >= 5.0:
                            print(f"[STT] 5ì´ˆ ì¹¨ë¬µ ê°ì§€, ë…¹ìŒ ì¤‘ë‹¨")
                            break
                            
                    except queue.Empty:
                        time.sleep(0.01)
                    
                    # UI ì—…ë°ì´íŠ¸
                    progress = elapsed_time / max_duration
                    progress_bar.progress(progress)
                    
                    if speech_detected:
                        silence_time = current_time - last_speech_time
                        if silence_time < 5.0:
                            status_text.text(f"ğŸ™ï¸ ìŒì„± ì¸ì‹ ì¤‘... (ì¹¨ë¬µ: {silence_time:.1f}ì´ˆ)")
                        else:
                            status_text.text("ğŸ™ï¸ ìŒì„± ì…ë ¥ ì™„ë£Œ!")
                    else:
                        remaining_time = max_duration - elapsed_time
                        status_text.text(f"ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”... (ë‚¨ì€ ì‹œê°„: {remaining_time:.1f}ì´ˆ)")
            
            if not recorded_data:
                st.warning("ìŒì„±ì´ ë…¹ìŒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return ""
            
            # ë…¹ìŒëœ ë°ì´í„° ê²°í•©
            recording = np.concatenate(recorded_data, axis=0)
            
            # ìŒì„± ì¸ì‹ ì²˜ë¦¬ ì¤‘ í‘œì‹œ
            status_text.text("ğŸ”„ ìŒì„±ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            
            # WAV íŒŒì¼ë¡œ ì €ì¥
            temp_wav = self.tmp_dir / f"recording_{int(time.time())}.wav"
            with wave.open(str(temp_wav), 'wb') as wav_file:
                wav_file.setnchannels(channels)
                wav_file.setsampwidth(2)  # 16-bit
                wav_file.setframerate(sample_rate)
                wav_file.writeframes(recording.tobytes())
            
            # OpenAI STT API í˜¸ì¶œ
            with open(temp_wav, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="ko"  # í•œêµ­ì–´ ëª…ì‹œ
                )
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(temp_wav)
            
            result = transcript.text.strip()
            print(f"[STT] ì¸ì‹ ê²°ê³¼: {result}")
            
            # ì¸ì‹ ê²°ê³¼ í™”ë©´ì— í‘œì‹œ
            if result:
                st.markdown("### ğŸ’¬ ê³ ê°ë‹˜ì´ ë§ì”€í•˜ì‹  ë‚´ìš©")
                st.success(f'ğŸ¤ ì¸ì‹ëœ ìŒì„±: "{result}"')
                
                # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
                st.info(f"ğŸ“ ìŒì„± ì¸ì‹ ì™„ë£Œ! ê¸¸ì´: {len(result)}ì")
                
                # ìë™ ìŠ¤í¬ë¡¤ì„ ìœ„í•œ JavaScript ì‹¤í–‰
                st.markdown("""
                <script>
                setTimeout(function() {
                    window.scrollTo(0, document.body.scrollHeight);
                }, 100);
                </script>
                """, unsafe_allow_html=True)
            else:
                st.warning("ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            return result if result else ""
            
        except Exception as e:
            print(f"[STT] ì˜¤ë¥˜: {e}")
            st.error(f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}")
            return ""
    
    def extract_allergens_from_voice(self, user_voice_text: str) -> list:
        """ì‚¬ìš©ì ìŒì„±ì—ì„œ ì•Œë ˆë¥´ê¸° ì¬ë£Œ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜"""
        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì•Œë ˆë¥´ê¸° ì¬ë£Œ ëª©ë¡
            available_allergens = ["ë‹¬ê±€", "í† ë§ˆí† ", "ìƒˆìš°", "ì¡°ê°œë¥˜", "ë‹­ê³ ê¸°", "ë•…ì½©", "ì‡ ê³ ê¸°", "ë¼ì§€ê³ ê¸°", "í˜¸ë‘"]
            
            # OpenAI GPT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì•Œë ˆë¥´ê¸° ì¬ë£Œ ì¶”ì¶œ
            system_prompt = f"""
            ì‚¬ìš©ìì˜ ìŒì„±ì—ì„œ ì•Œë ˆë¥´ê¸°ê°€ ìˆëŠ” ìŒì‹ ì¬ë£Œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
            
            ì‚¬ìš© ê°€ëŠ¥í•œ ì•Œë ˆë¥´ê¸° ì¬ë£Œ ëª©ë¡:
            {', '.join(available_allergens)}
            
            ê·œì¹™:
            1. ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì¬ë£Œ ì¤‘ ìœ„ ëª©ë¡ì— ìˆëŠ” ê²ƒë§Œ ì¶”ì¶œ
            2. "ì—†ìŒ", "ì—†ì–´ìš”", "ì•ˆ ìˆì–´ìš”" ë“±ì´ í¬í•¨ë˜ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜
            3. JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜ (ì˜ˆ: ["ë‹¬ê±€", "í† ë§ˆí† "])
            4. ëª©ë¡ì— ì—†ëŠ” ì¬ë£ŒëŠ” ë¬´ì‹œ
            5. êµ´, ê°€ë¦¬ë¹„ëŠ” "ì¡°ê°œë¥˜"ë¡œ í†µí•©
            """
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ì‚¬ìš©ì ìŒì„± ë‚´ìš©: {user_voice_text}"}
                ],
                temperature=0.1,
                max_tokens=100
            )
            
            # JSON ì‘ë‹µ íŒŒì‹±
            result_text = response.choices[0].message.content.strip()
            print(f"[ì•Œë ˆë¥´ê¸° ì¶”ì¶œ] GPT ì‘ë‹µ: {result_text}")
            
            # JSON íŒŒì‹±
            try:
                allergens = json.loads(result_text)
                if isinstance(allergens, list):
                    # ìœ íš¨í•œ ì•Œë ˆë¥´ê¸° ì¬ë£Œë§Œ í•„í„°ë§
                    valid_allergens = [item for item in allergens if item in available_allergens]
                    print(f"[ì•Œë ˆë¥´ê¸° ì¶”ì¶œ] ì¶”ì¶œëœ ì•Œë ˆë¥´ê¸°: {valid_allergens}")
                    return valid_allergens
                else:
                    print(f"[ì•Œë ˆë¥´ê¸° ì¶”ì¶œ] ì˜ëª»ëœ ì‘ë‹µ í˜•ì‹: {allergens}")
                    return []
            except json.JSONDecodeError:
                print(f"[ì•Œë ˆë¥´ê¸° ì¶”ì¶œ] JSON íŒŒì‹± ì‹¤íŒ¨: {result_text}")
                return []
            
        except Exception as e:
            print(f"[ì•Œë ˆë¥´ê¸° ì¶”ì¶œ] ì˜¤ë¥˜: {e}")
            st.error(f"ì•Œë ˆë¥´ê¸° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def extract_diet_from_voice(self, user_voice_text: str) -> str:
        """ì‚¬ìš©ì ìŒì„±ì—ì„œ ì‹ë‹¨ ìœ í˜• ì¶”ì¶œ"""
        try:
            # OpenAI GPT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹ë‹¨ ìœ í˜• ì¶”ì¶œ
            system_prompt = """
            ì‚¬ìš©ìì˜ ìŒì„±ì—ì„œ ì‹ë‹¨ ìœ í˜•ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
            
            ê°€ëŠ¥í•œ ì‹ë‹¨ ìœ í˜•:
            - "ë¹„ê±´" (ì™„ì „ ì±„ì‹ì£¼ì˜ì)
            - "ì±„ì‹" ë˜ëŠ” "ë² ì§€í…Œë¦¬ì–¸" (ì±„ì‹ì£¼ì˜ì)
            - "ì¼ë°˜" (íŠ¹ë³„í•œ ì‹ë‹¨ ì—†ìŒ)
            
            ê·œì¹™:
            1. ì‚¬ìš©ìê°€ "ë¹„ê±´", "ë¹„ê±´ì‹", "ì™„ì „ì±„ì‹" ë“±ì„ ì–¸ê¸‰í•˜ë©´ "ë¹„ê±´" ë°˜í™˜
            2. ì‚¬ìš©ìê°€ "ì±„ì‹", "ë² ì§€í…Œë¦¬ì–¸", "ì±„ì‹ì£¼ì˜" ë“±ì„ ì–¸ê¸‰í•˜ë©´ "ì±„ì‹" ë°˜í™˜
            3. ìœ„ì— í•´ë‹¹í•˜ì§€ ì•Šê±°ë‚˜ "ì•„ë‹ˆë‹¤", "ì¼ë°˜", "ì—†ë‹¤" ë“±ì´ë©´ "ì¼ë°˜" ë°˜í™˜
            4. ë°˜ë“œì‹œ "ë¹„ê±´", "ì±„ì‹", "ì¼ë°˜" ì¤‘ í•˜ë‚˜ë§Œ ë°˜í™˜
            """
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ì‚¬ìš©ì ìŒì„± ë‚´ìš©: {user_voice_text}"}
                ],
                temperature=0.1,
                max_tokens=50
            )
            
            result = response.choices[0].message.content.strip()
            print(f"[ì‹ë‹¨ ì¶”ì¶œ] GPT ì‘ë‹µ: {result}")
            
            # ê²°ê³¼ ê²€ì¦
            if "ë¹„ê±´" in result:
                return "ë¹„ê±´"
            elif "ì±„ì‹" in result:
                return "ì±„ì‹"
            else:
                return "ì¼ë°˜"
            
        except Exception as e:
            print(f"[ì‹ë‹¨ ì¶”ì¶œ] ì˜¤ë¥˜: {e}")
            return "ì¼ë°˜"

    def extract_category_from_voice(self, user_voice_text: str) -> str:
        """ì‚¬ìš©ì ìŒì„±ì—ì„œ ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
        try:
            system_prompt = """
            ì‚¬ìš©ìì˜ ìŒì„±ì—ì„œ ì›í•˜ëŠ” ë©”ë‰´ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
            
            ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬:
            - "ë©”ì¸" (ë°°ê³ í”„ë‹¤, ë“ ë“ í•˜ê²Œ, ì‹ì‚¬, í–„ë²„ê±°, ì¹˜í‚¨, ë°¥ ë“±)
            - "ì‚¬ì´ë“œ" (ê°„ì‹, ê°€ë³ê²Œ, ì‚¬ì´ë“œë©”ë‰´, ê°ìíŠ€ê¹€, ì¹˜í‚¨ë„ˆê²Ÿ ë“±)
            - "ìŒë£Œ" (ê°ˆì¦, ëª©ë§ˆë¥´ë‹¤, ìŒë£Œìˆ˜, ì½œë¼, ì£¼ìŠ¤, ì»¤í”¼ ë“±)
            - "ë””ì €íŠ¸" (ë‹¬ë‹¤, ë‹¬ì½¤í•˜ë‹¤, ë””ì €íŠ¸, ì•„ì´ìŠ¤í¬ë¦¼, ì¼€ì´í¬ ë“±)
            
            ê·œì¹™:
            1. ë°°ê³ í””ì´ë‚˜ ë“ ë“ í•œ ì‹ì‚¬ë¥¼ ì›í•˜ë©´ "ë©”ì¸"
            2. ê°€ë²¼ìš´ ê°„ì‹ì´ë‚˜ ì‚¬ì´ë“œë¥¼ ì›í•˜ë©´ "ì‚¬ì´ë“œ"  
            3. ê°ˆì¦ì´ë‚˜ ìŒë£Œë¥¼ ì›í•˜ë©´ "ìŒë£Œ"
            4. ë‹¬ì½¤í•œ ê²ƒì´ë‚˜ ë””ì €íŠ¸ë¥¼ ì›í•˜ë©´ "ë””ì €íŠ¸"
            5. ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ "ë©”ì¸" ë°˜í™˜
            6. ë°˜ë“œì‹œ "ë©”ì¸", "ì‚¬ì´ë“œ", "ìŒë£Œ", "ë””ì €íŠ¸" ì¤‘ í•˜ë‚˜ë§Œ ë°˜í™˜
            """
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ì‚¬ìš©ì ìŒì„± ë‚´ìš©: {user_voice_text}"}
                ],
                temperature=0.1,
                max_tokens=50
            )
            
            result = response.choices[0].message.content.strip()
            print(f"[ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ] GPT ì‘ë‹µ: {result}")
            
            # ê²°ê³¼ ê²€ì¦
            valid_categories = ["ë©”ì¸", "ì‚¬ì´ë“œ", "ìŒë£Œ", "ë””ì €íŠ¸"]
            for category in valid_categories:
                if category in result:
                    return category
            
            return "ë©”ì¸"  # ê¸°ë³¸ê°’
            
        except Exception as e:
            print(f"[ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ] ì˜¤ë¥˜: {e}")
            return "ë©”ì¸"

    def start_complete_voice_ordering(self) -> dict:
        """ìŒì„± ì£¼ë¬¸ ì‹œì‘ - ì•Œë ˆë¥´ê¸°, ì‹ë‹¨, ì¹´í…Œê³ ë¦¬ í™•ì¸"""
        try:
            # 1ë‹¨ê³„: ì•Œë ˆë¥´ê¸° í™•ì¸
            allergy_question = """ì•ˆë…•í•˜ì„¸ìš”! ì£¼ë¬¸ì„ ë°›ê² ìŠµë‹ˆë‹¤. 
            ë‹¬ê±€, í† ë§ˆí† , ìƒˆìš°, ì¡°ê°œë¥˜ (êµ´, ê°€ë¦¬ë¹„), ë‹­ê³ ê¸°, ë•…ì½©, ì‡ ê³ ê¸°, ë¼ì§€ê³ ê¸°, í˜¸ë‘ ì¤‘ ì•Œë ˆë¥´ê¸° ìˆëŠ” ì¬ë£Œê°€ ìˆìœ¼ì‹ ê°€ìš”?
            ì•Œë ˆë¥´ê¸°ê°€ ì—†ìœ¼ì‹œë©´ 'ì—†ìŒ'ì´ë¼ê³  ë§ì”€í•´ ì£¼ì„¸ìš”."""
            
            # ìŒì„± ì•ˆë‚´ ì‹œì‘
            st.info("ğŸ”Š ìŒì„± ì•ˆë‚´ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
            time.sleep(1)
            
            self.text_to_speech(allergy_question)
            
            # ì‚¬ìš©ìê°€ ì‘ë‹µí•  ì¤€ë¹„ë¥¼ í•  ìˆ˜ ìˆë„ë¡ ì ì‹œ ëŒ€ê¸°
            st.info("ğŸ™ï¸ ì´ì œ ë§ì”€í•´ ì£¼ì„¸ìš”. ì¶©ë¶„íˆ ìƒê°í•˜ì‹  í›„ ë‹µë³€í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.")
            st.info("ğŸ¯ ì˜ˆì‹œ: 'ë‹¬ê±€ ì•Œë ˆë¥´ê¸° ìˆì–´ìš”' ë˜ëŠ” 'ì—†ìŒ'")
            time.sleep(3)  # 3ì´ˆ ëŒ€ê¸°
            
            # ì•Œë ˆë¥´ê¸° ì‘ë‹µ ë°›ê¸°
            user_allergy_response = self.speech_to_text(duration=15.0)  # 15ì´ˆë¡œ ì—°ì¥
            if not user_allergy_response:
                st.warning("ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
                return {"allergens": [], "diet": "ì¼ë°˜", "category": "ë©”ì¸"}
            
            # ì•Œë ˆë¥´ê¸° ì¬ë£Œ ì¶”ì¶œ
            allergens = self.extract_allergens_from_voice(user_allergy_response)
            
            # ì•Œë ˆë¥´ê¸° í™•ì¸ ë©”ì‹œì§€
            if allergens:
                allergy_confirmation = f"ë„¤, {', '.join(allergens)} ì•Œë ˆë¥´ê¸°ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤."
            else:
                allergy_confirmation = "ë„¤, ì•Œë ˆë¥´ê¸°ê°€ ì—†ìœ¼ì‹œêµ°ìš”."
            
            st.markdown("---")
            self.text_to_speech(allergy_confirmation)
            
            # 2ë‹¨ê³„: ì‹ë‹¨ í™•ì¸
            diet_question = """ì´ì œ ì‹ë‹¨ì— ëŒ€í•´ ì—¬ì­¤ë³´ê² ìŠµë‹ˆë‹¤.
            ë¹„ê±´ (ì™„ì „ ì±„ì‹ì£¼ì˜)ì´ì‹œê±°ë‚˜ ë² ì§€í…Œë¦¬ì–¸ (ì±„ì‹ì£¼ì˜)ì´ì‹ ê°€ìš”?
            í•´ë‹¹ë˜ì‹œë©´ ë§ì”€í•´ ì£¼ì‹œê³ , ì•„ë‹ˆì‹œë©´ 'ì•„ë‹ˆë‹¤' ë˜ëŠ” 'ì¼ë°˜'ì´ë¼ê³  ë§ì”€í•´ ì£¼ì„¸ìš”."""
            
            st.markdown("---")
            self.text_to_speech(diet_question)
            
            # ì‚¬ìš©ìê°€ ì‘ë‹µí•  ì¤€ë¹„ë¥¼ í•  ìˆ˜ ìˆë„ë¡ ì ì‹œ ëŒ€ê¸°
            st.info("ğŸ™ï¸ ì´ì œ ë§ì”€í•´ ì£¼ì„¸ìš”. ì¶©ë¶„íˆ ìƒê°í•˜ì‹  í›„ ë‹µë³€í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.")
            st.info("ğŸ¯ ì˜ˆì‹œ: 'ë¹„ê±´ì´ì—ìš”' ë˜ëŠ” 'ì±„ì‹' ë˜ëŠ” 'ì¼ë°˜'")
            time.sleep(3)  # 3ì´ˆ ëŒ€ê¸°
            
            # ì‹ë‹¨ ì‘ë‹µ ë°›ê¸°
            user_diet_response = self.speech_to_text(duration=15.0)  # 15ì´ˆë¡œ ì—°ì¥
            if not user_diet_response:
                st.warning("ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•„ ì¼ë°˜ ì‹ë‹¨ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
                diet_type = "ì¼ë°˜"
            else:
                diet_type = self.extract_diet_from_voice(user_diet_response)
            
            # ì‹ë‹¨ í™•ì¸ ë©”ì‹œì§€
            if diet_type == "ë¹„ê±´":
                diet_confirmation = "ë„¤, ë¹„ê±´ ì‹ë‹¨ìœ¼ë¡œ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤. ë™ë¬¼ì„± ì¬ë£Œê°€ í¬í•¨ëœ ë©”ë‰´ëŠ” ì œì™¸í•˜ê² ìŠµë‹ˆë‹¤."
            elif diet_type == "ì±„ì‹":
                diet_confirmation = "ë„¤, ì±„ì‹ ì‹ë‹¨ìœ¼ë¡œ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤. ê³ ê¸°ë¥˜ê°€ í¬í•¨ëœ ë©”ë‰´ëŠ” ì œì™¸í•˜ê² ìŠµë‹ˆë‹¤."
            else:
                diet_confirmation = "ë„¤, ì¼ë°˜ ì‹ë‹¨ìœ¼ë¡œ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤."
            
            st.markdown("---")
            self.text_to_speech(diet_confirmation)
            
            # 3ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ í™•ì¸
            category_question = """ë§ˆì§€ë§‰ìœ¼ë¡œ ì–´ë–¤ ì¢…ë¥˜ì˜ ìŒì‹ì„ ì›í•˜ì‹œëŠ”ì§€ ì—¬ì­¤ë³´ê² ìŠµë‹ˆë‹¤.
            ë§ì´ ë°°ê³ í”„ì‹œë‹¤ë©´ ë“ ë“ í•œ ë©”ì¸ ìš”ë¦¬, ê°€ë³ê²Œ ë“œì‹œê³  ì‹¶ë‹¤ë©´ ì‚¬ì´ë“œ ë©”ë‰´, 
            ê°ˆì¦ì´ ë‚˜ì‹ ë‹¤ë©´ ìŒë£Œ, ë‹¬ì½¤í•œ ê²ƒì´ ë“œì‹œê³  ì‹¶ë‹¤ë©´ ë””ì €íŠ¸ ì¤‘ì—ì„œ ë§ì”€í•´ ì£¼ì„¸ìš”.
            ë˜ëŠ” 'ë°°ê³ í”„ë‹¤', 'ê°ˆì¦ë‚œë‹¤', 'ë‹¬ë‹¬í•œê²Œ ë¨¹ê³ ì‹¶ë‹¤' ë“±ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì…”ë„ ë©ë‹ˆë‹¤."""
            
            st.markdown("---")
            self.text_to_speech(category_question)
            
            # ì‚¬ìš©ìê°€ ì‘ë‹µí•  ì¤€ë¹„ë¥¼ í•  ìˆ˜ ìˆë„ë¡ ì ì‹œ ëŒ€ê¸°
            st.info("ğŸ™ï¸ ì´ì œ ë§ì”€í•´ ì£¼ì„¸ìš”. ì¶©ë¶„íˆ ìƒê°í•˜ì‹  í›„ ë‹µë³€í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.")
            st.info("ğŸ¯ ì˜ˆì‹œ: 'ë°°ê³ íŒŒìš”' ë˜ëŠ” 'ê°ˆì¦ë‚˜ìš”' ë˜ëŠ” 'ë‹¬ë‹¬í•œê²Œ ì¢‹ì•„ìš”'")
            time.sleep(3)  # 3ì´ˆ ëŒ€ê¸°
            
            # ì¹´í…Œê³ ë¦¬ ì‘ë‹µ ë°›ê¸°
            user_category_response = self.speech_to_text(duration=15.0)  # 15ì´ˆë¡œ ì—°ì¥
            if not user_category_response:
                st.warning("ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•„ ë©”ì¸ ë©”ë‰´ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
                category_type = "ë©”ì¸"
            else:
                category_type = self.extract_category_from_voice(user_category_response)
            
            # ì¹´í…Œê³ ë¦¬ í™•ì¸ ë©”ì‹œì§€
            category_messages = {
                "ë©”ì¸": "ë„¤, ë“ ë“ í•œ ë©”ì¸ ìš”ë¦¬ë¡œ ì¤€ë¹„í•˜ê² ìŠµë‹ˆë‹¤.",
                "ì‚¬ì´ë“œ": "ë„¤, ê°€ë²¼ìš´ ì‚¬ì´ë“œ ë©”ë‰´ë¡œ ì¤€ë¹„í•˜ê² ìŠµë‹ˆë‹¤.",
                "ìŒë£Œ": "ë„¤, ì‹œì›í•œ ìŒë£Œë¡œ ì¤€ë¹„í•˜ê² ìŠµë‹ˆë‹¤.",
                "ë””ì €íŠ¸": "ë„¤, ë‹¬ì½¤í•œ ë””ì €íŠ¸ë¡œ ì¤€ë¹„í•˜ê² ìŠµë‹ˆë‹¤."
            }
            
            category_confirmation = category_messages.get(category_type, "ë„¤, ë©”ì¸ ìš”ë¦¬ë¡œ ì¤€ë¹„í•˜ê² ìŠµë‹ˆë‹¤.")
            
            st.markdown("---")
            self.text_to_speech(category_confirmation)
            
            # ìµœì¢… ì™„ë£Œ ë©”ì‹œì§€
            final_message = "ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì¡°ê±´ì— ë§ëŠ” ë©”ë‰´ë¥¼ ìë™ìœ¼ë¡œ ì„ íƒí•´ì„œ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            st.markdown("---")
            self.text_to_speech(final_message)
            
            return {"allergens": allergens, "diet": diet_type, "category": category_type}
            
        except Exception as e:
            print(f"[ìŒì„± ì£¼ë¬¸] ì˜¤ë¥˜: {e}")
            st.error(f"ìŒì„± ì£¼ë¬¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return {"allergens": [], "diet": "ì¼ë°˜", "category": "ë©”ì¸"}
    
    def start_allergy_voice_ordering(self) -> list:
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ (deprecated)"""
        result = self.start_complete_voice_ordering()
        return result["allergens"]

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
voice_ordering = None

def get_voice_ordering_instance():
    """VoiceOrdering ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤ íŒ¨í„´)"""
    global voice_ordering
    if voice_ordering is None:
        try:
            voice_ordering = VoiceOrdering()
        except Exception as e:
            st.error(f"ìŒì„± ì£¼ë¬¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    return voice_ordering

def start_voice_allergy_check():
    """ìŒì„± ì•Œë ˆë¥´ê¸° í™•ì¸ ì‹œì‘ (í˜¸í™˜ì„±ìš© - deprecated)"""
    voice_system = get_voice_ordering_instance()
    if voice_system:
        return voice_system.start_allergy_voice_ordering()
    return []

def start_complete_voice_ordering():
    """ì™„ì „í•œ ìŒì„± ì£¼ë¬¸ ì‹œì‘ - ì•Œë ˆë¥´ê¸° ë° ì‹ë‹¨ í™•ì¸"""
    voice_system = get_voice_ordering_instance()
    if voice_system:
        return voice_system.start_complete_voice_ordering()
    return {"allergens": [], "diet": "ì¼ë°˜"}